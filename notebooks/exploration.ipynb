{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ddf89e",
   "metadata": {},
   "source": [
    "# Alzheimer’s Disease Pathway — Min-Cut Pipeline\n",
    "\n",
    "What this notebook does\n",
    "\n",
    "- 1. Fetch KEGG hsa05010 (Alzheimer’s disease) genes via KEGG REST API\n",
    "- 2. Map to gene symbols; query STRING API for PPI network (human 9606)\n",
    "- 3. Build a weighted NetworkX graph\n",
    "- 4. Compute:\n",
    "  - Global min-cut (Stoer–Wagner, weighted)\n",
    "  - s–t min edge cut (sources: APP/PSEN1/PSEN2/MAPT; sinks: CASP3/CASP8/APAF1)\n",
    "  - Karger randomized min-cut on unweighted graph (10/100/1000 trials)\n",
    "\n",
    "5.  Visualize network snapshot (cut edges) and a trials-vs-average plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(sys.version)\n",
    "print(\"NetworkX:\", nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79106ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEGG_BASE = \"http://rest.kegg.jp\"\n",
    "KEGG_PATHWAY_ID = \"hsa05010\"  # Alzheimer's disease\n",
    "\n",
    "def kegg_link_hsa(pathway_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    KEGG: link hsa <pathway> → pathway-to-gene rows: path:hsa05010 \\t hsa:351\n",
    "    \"\"\"\n",
    "    url = f\"{KEGG_BASE}/link/hsa/{pathway_id}\"\n",
    "    r = requests.get(url, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    rows = [line.split(\"\\t\") for line in r.text.strip().splitlines()]\n",
    "    df = pd.DataFrame(rows, columns=[\"pathway\", \"hsa_id\"])\n",
    "    return df\n",
    "\n",
    "def kegg_get_gene_symbols(hsa_ids: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    KEGG: get hsa:XXXX blocks; parse NAME line for the primary gene symbol.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    BATCH = 50\n",
    "    for i in range(0, len(hsa_ids), BATCH):\n",
    "        batch = hsa_ids[i:i+BATCH]\n",
    "        ids_str = \"+\".join(batch)\n",
    "        url = f\"{KEGG_BASE}/get/{ids_str}\"\n",
    "        r = requests.get(url, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        # Split into entries using 'ENTRY' as delimiter\n",
    "        entries = r.text.split(\"ENTRY\")\n",
    "        for ent in entries:\n",
    "            if not ent.strip():\n",
    "                continue\n",
    "            # Try to find an 'hsa:' token in the block (gene id)\n",
    "            tokens = [t for t in ent.split() if t.startswith(\"hsa:\")]\n",
    "            hsa_id = tokens[0] if tokens else None\n",
    "\n",
    "            # Parse NAME line: e.g., \"NAME        APP; amyloid beta precursor protein\"\n",
    "            symbol = None\n",
    "            for ln in ent.splitlines():\n",
    "                if ln.strip().startswith(\"NAME\"):\n",
    "                    rest = ln.split(\"NAME\", 1)[1].strip()\n",
    "                    if \";\" in rest:\n",
    "                        symbol = rest.split(\";\")[0].strip()\n",
    "                    else:\n",
    "                        symbol = rest.split(\",\")[0].strip()\n",
    "                    break\n",
    "            if hsa_id and symbol:\n",
    "                chunks.append((hsa_id, symbol))\n",
    "    return pd.DataFrame(chunks, columns=[\"hsa_id\", \"gene_symbol\"])\n",
    "\n",
    "# Fetch KEGG genes\n",
    "link_df = kegg_link_hsa(KEGG_PATHWAY_ID)\n",
    "hsa_ids = sorted(link_df[\"hsa_id\"].unique().tolist())\n",
    "genes_df = kegg_get_gene_symbols(hsa_ids)\n",
    "print(\"Pathway:\", KEGG_PATHWAY_ID, \"| genes:\", len(genes_df))\n",
    "display(genes_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_BASE = \"https://string-db.org/api\"\n",
    "STRING_FORMAT = \"tsv\"\n",
    "STRING_METHOD = \"network\"\n",
    "SPECIES = 9606\n",
    "SCORE_CUTOFF = 700  # high confidence (0..1000)\n",
    "\n",
    "def string_network_from_genes(genes: list, species: int = 9606, score_cutoff: int = 700) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    STRING 'tsv/network' API: pass identifiers via query (URL-encoded newline %0d).\n",
    "    Returns a TSV where preferredName_A/B and score (combined) are present.\n",
    "    \"\"\"\n",
    "    # STRING supports identifiers separated by '%0d' (CR). Works fine for symbols.\n",
    "    identifiers = \"%0d\".join(genes)\n",
    "    url = f\"{STRING_BASE}/{STRING_FORMAT}/{STRING_METHOD}?identifiers={identifiers}&species={species}&required_score={score_cutoff}\"\n",
    "    r = requests.get(url, timeout=90)\n",
    "    r.raise_for_status()\n",
    "    df = pd.read_csv(io.StringIO(r.text), sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "gene_list = genes_df[\"gene_symbol\"].dropna().unique().tolist()\n",
    "str_df = string_network_from_genes(gene_list, species=SPECIES, score_cutoff=SCORE_CUTOFF)\n",
    "print(f\"STRING edges (score ≥ {SCORE_CUTOFF}):\", len(str_df))\n",
    "display(str_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41571f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_string(df: pd.DataFrame, allowed_nodes: set) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Build undirected weighted graph from STRING network table.\n",
    "    Uses preferredName_A/B (or protein1/protein2 fallback) and score as weight.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    for _, row in df.iterrows():\n",
    "        a = row.get(\"preferredName_A\") or row.get(\"protein1\")\n",
    "        b = row.get(\"preferredName_B\") or row.get(\"protein2\")\n",
    "        if not a or not b:\n",
    "            continue\n",
    "        if a not in allowed_nodes or b not in allowed_nodes:\n",
    "            continue\n",
    "        w = int(row.get(\"score\") or row.get(\"combined_score\") or 0)\n",
    "        if G.has_edge(a, b):\n",
    "            # keep max weight if duplicates appear\n",
    "            if w > G[a][b].get(\"weight\", 0):\n",
    "                G[a][b][\"weight\"] = w\n",
    "        else:\n",
    "            G.add_edge(a, b, weight=w)\n",
    "    return G\n",
    "\n",
    "allowed = set(gene_list)\n",
    "G = build_graph_from_string(str_df, allowed)\n",
    "print(\"Nodes:\", G.number_of_nodes(), \"| Edges:\", G.number_of_edges())\n",
    "\n",
    "# Basic sanity: connected components\n",
    "comps = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "print(\"Connected components:\", len(comps), \"| largest size:\", len(comps[0]) if comps else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.connectivity import stoer_wagner, minimum_edge_cut\n",
    "\n",
    "def cut_edges_from_partition(G: nx.Graph, partition):\n",
    "    A, B = map(set, partition)\n",
    "    return [(u, v, G[u][v].get(\"weight\", 1))\n",
    "            for (u, v) in G.edges()\n",
    "            if (u in A and v in B) or (u in B and v in A)]\n",
    "\n",
    "# 5a) Global min-cut\n",
    "if G.number_of_nodes() > 1 and G.number_of_edges() > 0:\n",
    "    sw_value, sw_part = stoer_wagner(G, weight=\"weight\")\n",
    "    sw_edges = cut_edges_from_partition(G, sw_part)\n",
    "    print(\"Global min-cut value (weighted):\", sw_value, \"| edges in cut:\", len(sw_edges))\n",
    "else:\n",
    "    sw_value, sw_part, sw_edges = None, (set(), set()), []\n",
    "    print(\"Graph too small for global min-cut.\")\n",
    "\n",
    "# 5b) s–t min edge cut between selected biological sets\n",
    "sources = [g for g in [\"APP\", \"PSEN1\", \"PSEN2\", \"MAPT\"] if g in G]\n",
    "sinks   = [g for g in [\"CASP3\", \"CASP8\", \"APAF1\"] if g in G]\n",
    "\n",
    "def st_edge_cut_multi_source_sink(G: nx.Graph, sources, sinks):\n",
    "    \"\"\"\n",
    "    Try all (s, t) pairs and choose the smallest minimum_edge_cut (by edge count).\n",
    "    For small sets this is fine. Returns best pair and edge set.\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    best_pair = None\n",
    "    for s in sources:\n",
    "        for t in sinks:\n",
    "            if s == t:\n",
    "                continue\n",
    "            cut = minimum_edge_cut(G, s, t)  # edge set\n",
    "            if best is None or len(cut) < len(best):\n",
    "                best = cut\n",
    "                best_pair = (s, t)\n",
    "    return best_pair, best or set()\n",
    "\n",
    "st_pair, st_cut = (None, None), set()\n",
    "if sources and sinks:\n",
    "    st_pair, st_cut = st_edge_cut_multi_source_sink(G, sources, sinks)\n",
    "    print(\"Best s–t pair:\", st_pair, \"| s–t cut size (edges):\", len(st_cut))\n",
    "else:\n",
    "    print(\"Note: some source/sink genes absent → s–t cut may be empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa317bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def karger_min_cut_unweighted(G: nx.Graph, rng: random.Random):\n",
    "    \"\"\"\n",
    "    Classic Karger random contraction algorithm (unweighted).\n",
    "    We keep 'multiplicity' on edges formed by contraction to count parallel edges.\n",
    "    \"\"\"\n",
    "    H = G.copy()\n",
    "    H.remove_edges_from(nx.selfloop_edges(H))\n",
    "    # Initialize multiplicity = 1 for all edges\n",
    "    for u, v in H.edges():\n",
    "        if \"multiplicity\" not in H[u][v]:\n",
    "            H[u][v][\"multiplicity\"] = 1\n",
    "\n",
    "    while H.number_of_nodes() > 2:\n",
    "        u, v = rng.choice(list(H.edges()))\n",
    "        # Contract v into u\n",
    "        for nbr in list(H.neighbors(v)):\n",
    "            if nbr == u:\n",
    "                continue\n",
    "            mult = H[v][nbr].get(\"multiplicity\", 1)\n",
    "            if H.has_edge(u, nbr):\n",
    "                H[u][nbr][\"multiplicity\"] = H[u][nbr].get(\"multiplicity\", 1) + mult\n",
    "            else:\n",
    "                H.add_edge(u, nbr, multiplicity=mult)\n",
    "        H.remove_node(v)\n",
    "        if H.has_edge(u, u):\n",
    "            H.remove_edge(u, u)\n",
    "\n",
    "    cut_size = sum(data.get(\"multiplicity\", 1) for _, _, data in H.edges(data=True))\n",
    "    return cut_size\n",
    "\n",
    "def run_karger_trials(G: nx.Graph, trials: int, seed: int = 42):\n",
    "    rng = random.Random(seed)\n",
    "    # Use an unweighted copy (ignore 'weight' when contracting)\n",
    "    U = nx.Graph()\n",
    "    U.add_nodes_from(G.nodes())\n",
    "    U.add_edges_from(G.edges())  # no weights\n",
    "    vals = []\n",
    "    for _ in range(trials):\n",
    "        vals.append(karger_min_cut_unweighted(U, rng))\n",
    "    return vals\n",
    "\n",
    "trial_list = [10, 100, 1000]\n",
    "karger_results = {t: run_karger_trials(G, t, seed=123) for t in trial_list}\n",
    "pd.DataFrame({t: pd.Series(v) for t, v in karger_results.items()}).describe()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
